{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Federated Learning with Flower (`flwr`)\n",
        "\n",
        "[Flower](https://flower.dev/) (`flwr`) is a framework for building federated learning systems. The\n",
        "design of Flower is based on a few guiding principles:\n",
        "\n",
        "* **Customizable**: Federated learning systems vary wildly from one use case to\n",
        "  another. Flower allows for a wide range of different configurations depending\n",
        "  on the needs of each individual use case.\n",
        "\n",
        "* **Extendable**: Flower originated from a research project at the University of\n",
        "  Oxford, so it was built with AI research in mind. Many components can be\n",
        "  extended and overridden to build new state-of-the-art systems.\n",
        "\n",
        "* **Framework-agnostic**: Different machine learning frameworks have different strengths. Flower can be used with any machine learning framework, for example, [PyTorch](https://pytorch.org), [TensorFlow](https://tensorflow.org), [Hugging Face Transformers](https://huggingface.co/), [PyTorch Lightning](https://pytorchlightning.ai/), [MXNet](https://mxnet.apache.org/), [scikit-learn](https://scikit-learn.org/), [JAX](https://jax.readthedocs.io/), [TFLite](https://tensorflow.org/lite/), [Pandas](https://pandas.pydata.org/) for federated analytics, or even raw [NumPy](https://numpy.org/) for users who enjoy computing gradients by hand.\n",
        "\n",
        "* **Understandable**: Flower is written with maintainability in mind. The\n",
        "  community is encouraged to both read and contribute to the codebase."
      ],
      "metadata": {
        "id": "4MgnMBck5D_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flower with TensorFlow\n",
        "\n",
        "To start with, let' try to build a federated learning system using Flower and [TensorFlow](https://www.tensorflow.org/). \n",
        "\n",
        "### Install required packages\n",
        "\n",
        "1. Check out Python versions supporting both TensorFlow and Flower. ([Flower's](https://flower.dev/docs/installation.html#python-version) and [TensorFlow's](https://www.tensorflow.org/install) requirements) \n",
        "\n",
        "2. Create a virtual environment using [conda](https://docs.conda.io/en/latest/), [virtualenv](https://virtualenv.pypa.io/en/latest/) or other tools. Let's say you use Anaconda. \n",
        "\n",
        "```shell\n",
        "conda create -n flwr python # you can specify a Python version: \"python\" => \"python=3.10\"\n",
        "```\n",
        "\n",
        "3. Activate that environemnt.\n",
        "\n",
        "```shell\n",
        "conda activate flwr\n",
        "```\n",
        "\n",
        "4. Install TensorFlow and Flower\n",
        "\n",
        "```shell\n",
        "# Install Tensorflow\n",
        "# Check out https://www.tensorflow.org/install/pip for latest instruction\n",
        "# You may need to change codatoolkit and cudnn version depending on your setup and any future change to TensorFlow\n",
        "conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
        "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
        "python3 -m pip install tensorflow\n",
        "# Verify install:\n",
        "python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
        "\n",
        "# Install Flower\n",
        "pip install flwr\n",
        "```\n",
        "\n",
        "And we are good to go!\n",
        "\n",
        "### Design server and clients\n",
        "\n",
        "Flower has made this step very easy. \n",
        "\n",
        "#### Clients\n",
        "\n",
        "Create a file `client.py`. And in that file, write\n",
        "\n",
        "```python\n",
        "import flwr as fl\n",
        "import tensorflow as tf\n",
        "```\n",
        "\n",
        "to import the required modules. \n",
        "\n",
        "After that, let's load the famous [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset to do a simple image classification job. \n",
        "\n",
        "```python\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "```\n",
        "\n",
        "For the model, let's use [MobileNetV2](https://arxiv.org/abs/1801.04381), a convolutional neural network (CNN) architecture that seeks to perform well on mobile devices, with 10 output classes.\n",
        "\n",
        "```python\n",
        "model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)\n",
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "```\n",
        "\n",
        "![mnv2](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-06_at_10.37.14_PM.png)\n",
        "\n",
        "The Flower server interacts with clients through an interface called `Client`. When the server selects a particular client for training, it sends training instructions over the network. The client receives those instructions and calls one of the `Client` methods to run your code (i.e., to train the neural network we defined earlier).\n",
        "\n",
        "Flower provides a convenience class called `NumPyClient` which makes it easier to implement the `Client` interface when your workload uses Keras. The `NumPyClient` interface defines three methods which can be implemented in the following way:\n",
        "\n",
        "```python\n",
        "class CifarClient(fl.client.NumPyClient):\n",
        "    def get_parameters(self, config):\n",
        "        return model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        model.set_weights(parameters)\n",
        "        model.fit(x_train, y_train, epochs=1, batch_size=32, steps_per_epoch=3)\n",
        "        return model.get_weights(), len(x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        model.set_weights(parameters)\n",
        "        loss, accuracy = model.evaluate(x_test, y_test)\n",
        "        return loss, len(x_test), {\"accuracy\": float(accuracy)}\n",
        "```\n",
        "\n",
        "Now create an instance of our class CifarClient and add one line to actually run this client:\n",
        "\n",
        "```python\n",
        "fl.client.start_numpy_client(server_address=\"[::]:8080\", client=CifarClient())\n",
        "```\n",
        "\n",
        "The string `\"[::]:8080\"` tells the client which server to connect to. In our case we can run the server and the client on the same machine, therefore we use `\"[::]:8080\"`. If we run a truly federated workload with the server and clients running on different machines, all that needs to change is the `server_address` we point the client at.\n",
        "\n",
        "#### Server\n",
        "\n",
        "Server setup is even easier as Flower has simplified more for us. Create a file `server.py` and in that file:\n",
        "\n",
        "```python\n",
        "import flwr as fl\n",
        "\n",
        "fl.server.start_server(config=fl.server.ServerConfig(num_rounds=3))\n",
        "```\n",
        "\n",
        "### Train the model\n",
        "\n",
        "1. Start the server:\n",
        "\n",
        "```shell\n",
        "python server.py\n",
        "```\n",
        "\n",
        "2. In a different terminal sessions, run\n",
        "\n",
        "```shell\n",
        "$ python client.py\n",
        "```\n",
        "\n",
        "to start a first client and in another terminal session run the same code for a second one.\n",
        "\n",
        "Voil√†! FL has started. You should be able to see in the server terminal:\n",
        "\n",
        "```shell\n",
        "INFO flower 2021-02-25 14:15:46,741 | app.py:76 | Flower server running (insecure, 3 rounds)\n",
        "INFO flower 2021-02-25 14:15:46,742 | server.py:72 | Getting initial parameters\n",
        "INFO flower 2021-02-25 14:16:01,770 | server.py:74 | Evaluating initial parameters\n",
        "INFO flower 2021-02-25 14:16:01,770 | server.py:87 | [TIME] FL starting\n",
        "DEBUG flower 2021-02-25 14:16:12,341 | server.py:165 | fit_round: strategy sampled 2 clients (out of 2)\n",
        "DEBUG flower 2021-02-25 14:21:17,235 | server.py:177 | fit_round received 2 results and 0 failures\n",
        "DEBUG flower 2021-02-25 14:21:17,512 | server.py:139 | evaluate: strategy sampled 2 clients\n",
        "DEBUG flower 2021-02-25 14:21:29,628 | server.py:149 | evaluate received 2 results and 0 failures\n",
        "DEBUG flower 2021-02-25 14:21:29,696 | server.py:165 | fit_round: strategy sampled 2 clients (out of 2)\n",
        "DEBUG flower 2021-02-25 14:25:59,917 | server.py:177 | fit_round received 2 results and 0 failures\n",
        "DEBUG flower 2021-02-25 14:26:00,227 | server.py:139 | evaluate: strategy sampled 2 clients\n",
        "DEBUG flower 2021-02-25 14:26:11,457 | server.py:149 | evaluate received 2 results and 0 failures\n",
        "DEBUG flower 2021-02-25 14:26:11,530 | server.py:165 | fit_round: strategy sampled 2 clients (out of 2)\n",
        "DEBUG flower 2021-02-25 14:30:43,389 | server.py:177 | fit_round received 2 results and 0 failures\n",
        "DEBUG flower 2021-02-25 14:30:43,630 | server.py:139 | evaluate: strategy sampled 2 clients\n",
        "DEBUG flower 2021-02-25 14:30:53,384 | server.py:149 | evaluate received 2 results and 0 failures\n",
        "INFO flower 2021-02-25 14:30:53,384 | server.py:122 | [TIME] FL finished in 891.6143046000007\n",
        "INFO flower 2021-02-25 14:30:53,385 | app.py:109 | app_fit: losses_distributed [(1, 2.3196680545806885), (2, 2.3202896118164062), (3, 2.1818180084228516)]\n",
        "INFO flower 2021-02-25 14:30:53,385 | app.py:110 | app_fit: accuracies_distributed []\n",
        "INFO flower 2021-02-25 14:30:53,385 | app.py:111 | app_fit: losses_centralized []\n",
        "INFO flower 2021-02-25 14:30:53,385 | app.py:112 | app_fit: accuracies_centralized []\n",
        "DEBUG flower 2021-02-25 14:30:53,442 | server.py:139 | evaluate: strategy sampled 2 clients\n",
        "DEBUG flower 2021-02-25 14:31:02,848 | server.py:149 | evaluate received 2 results and 0 failures\n",
        "INFO flower 2021-02-25 14:31:02,848 | app.py:121 | app_evaluate: federated loss: 2.1818180084228516\n",
        "INFO flower 2021-02-25 14:31:02,848 | app.py:125 | app_evaluate: results [('ipv4:127.0.0.1:57158', EvaluateRes(loss=2.1818180084228516, num_examples=10000, accuracy=0.0, metrics={'accuracy': 0.21610000729560852})), ('ipv4:127.0.0.1:57160', EvaluateRes(loss=2.1818180084228516, num_examples=10000, accuracy=0.0, metrics={'accuracy': 0.21610000729560852}))]\n",
        "INFO flower 2021-02-25 14:31:02,848 | app.py:127 | app_evaluate: failures [] flower 2020-07-15 10:07:56,396 | app.py:77 | app_evaluate: failures []\n",
        "```"
      ],
      "metadata": {
        "id": "D-JM_dWvwDMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further reading and experiments\n",
        "\n",
        "- [Flower documentation](https://flower.dev/docs/)\n",
        "\n",
        "- [TensorFlow documentation](https://www.tensorflow.org/)\n",
        "\n",
        "- [MobileNetV2 paper](https://arxiv.org/abs/1801.04381)\n",
        "\n",
        "- [TensorFlow Federated](https://www.tensorflow.org/federated)\n",
        "\n",
        "- [FATE](https://fate.fedai.org/)\n",
        "\n",
        "- [IBM FL](https://ibmfl.mybluemix.net/)"
      ],
      "metadata": {
        "id": "z6UoPApj6xSB"
      }
    }
  ]
}