{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["uq_80u0tJrP6","GCJn0MoGJkbK","szsmARK-JuJy","iN07Cv6PKMYq","-0QlCpo8KpoD","nscZtpcwK7Iz"],"toc_visible":true,"authorship_tag":"ABX9TyOSYi1L2ZEIAZEsxsqE+Dau"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Code for FedEraser\n","\n","Adapted from original code of [the FedEraser paper](https://ieeexplore.ieee.org/abstract/document/9521274).\n","\n","Create a virtual environment using conda by\n","\n","```shell\n","conda create -n federaser python=3.8.3\n","```\n","\n","and activating it\n","\n","```shell\n","conda activate federaser\n","```\n","\n","Then, install required packages\n","\n","```\n","# This file may be used to create an environment using:\n","# $ conda create --name <env> --file <this file>\n","# platform: linux-64\n","_libgcc_mutex=0.1=main\n","_openmp_mutex=5.1=1_gnu\n","_py-xgboost-mutex=2.0=cpu_0\n","blas=1.0=mkl\n","ca-certificates=2022.10.11=h06a4308_0\n","certifi=2022.9.24=py38h06a4308_0\n","cudatoolkit=10.2.89=hfd86e86_1\n","freetype=2.12.1=h4a9f257_0\n","giflib=5.2.1=h7b6447c_0\n","intel-openmp=2021.4.0=h06a4308_3561\n","joblib=1.1.1=py38h06a4308_0\n","jpeg=9e=h7f8727e_0\n","lcms2=2.12=h3be6417_0\n","ld_impl_linux-64=2.38=h1181459_1\n","lerc=3.0=h295c915_0\n","libdeflate=1.8=h7f8727e_5\n","libffi=3.3=he6710b0_2\n","libgcc-ng=11.2.0=h1234567_1\n","libgfortran-ng=7.5.0=ha8ba4b0_17\n","libgfortran4=7.5.0=ha8ba4b0_17\n","libgomp=11.2.0=h1234567_1\n","libpng=1.6.37=hbc83047_0\n","libstdcxx-ng=11.2.0=h1234567_1\n","libtiff=4.4.0=hecacb30_2\n","libwebp=1.2.4=h11a3e52_0\n","libwebp-base=1.2.4=h5eee18b_0\n","libxgboost=1.5.0=h6a678d5_2\n","lz4-c=1.9.3=h295c915_1\n","mkl=2020.2=256\n","mkl-service=2.3.0=py38he904b0f_0\n","mkl_fft=1.3.0=py38h54f3939_0\n","mkl_random=1.1.1=py38h0573a6f_0\n","ncurses=6.3=h5eee18b_3\n","ninja=1.10.2=h06a4308_5\n","ninja-base=1.10.2=hd09550d_5\n","numpy=1.18.5=py38ha1c710e_0\n","numpy-base=1.18.5=py38hde5b4d6_0\n","openssl=1.1.1s=h7f8727e_0\n","pandas=1.2.4=py38ha9443f7_0\n","pillow=9.2.0=py38hace64e9_1\n","pip=22.2.2=py38h06a4308_0\n","py-xgboost=1.5.0=py38h06a4308_2\n","python=3.8.3=hcff3b4d_2\n","python-dateutil=2.8.2=pyhd3eb1b0_0\n","pytorch=1.6.0=py3.8_cuda10.2.89_cudnn7.6.5_0\n","pytz=2022.1=py38h06a4308_0\n","readline=8.2=h5eee18b_0\n","scikit-learn=0.23.1=py38h423224d_0\n","scipy=1.5.2=py38h0b6359f_0\n","setuptools=65.5.0=py38h06a4308_0\n","six=1.16.0=pyhd3eb1b0_1\n","sqlite=3.39.3=h5082296_0\n","threadpoolctl=2.2.0=pyh0d69192_0\n","tk=8.6.12=h1ccaba5_0\n","torchvision=0.7.0=py38_cu102\n","wheel=0.37.1=pyhd3eb1b0_0\n","xz=5.2.6=h5eee18b_0\n","zlib=1.2.13=h5eee18b_0\n","zstd=1.5.2=ha4553b6_0\n","```\n","\n","Put all the below files in the same directory and run \n","\n","```shell\n","python Fed_Unlearn_main.py\n","```"],"metadata":{"id":"zwF7YeO5Inzj"}},{"cell_type":"markdown","source":["# `data_preprocess.py`"],"metadata":{"id":"uq_80u0tJrP6"}},{"cell_type":"markdown","source":["```python\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import Dataset,TensorDataset\n","from torchvision import datasets, transforms\n","from sklearn.preprocessing import LabelEncoder,OneHotEncoder,MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"Function: load data\"\"\"\n","def data_init(FL_params):\n","    \n","    kwargs = {'num_workers': 0, 'pin_memory': True} if FL_params.cuda_state else {}\n","    trainset, testset = data_set(FL_params.data_name)\n","    test_loader = DataLoader(testset, batch_size=FL_params.test_batch_size, shuffle=True, **kwargs)\n","\n","    split_index = [int(trainset.__len__()/FL_params.N_total_client)]*(FL_params.N_total_client-1)\n","    split_index.append(int(trainset.__len__() - int(trainset.__len__()/FL_params.N_total_client)*(FL_params.N_total_client-1)))\n","    client_dataset = torch.utils.data.random_split(trainset, split_index)\n","\n","    client_loaders = []\n","    for ii in range(FL_params.N_total_client):\n","        client_loaders.append(DataLoader(client_dataset[ii], FL_params.local_batch_size, shuffle=True, **kwargs))\n","\n","    return client_loaders, test_loader\n","\n","\n","\"\"\"Function: load data\"\"\"\n","def data_init_with_shadow(FL_params):\n","    \n","    kwargs = {'num_workers': 0, 'pin_memory': True} if FL_params.cuda_state else {}\n","    whole_trainset, whole_testset = data_set(FL_params.data_name)\n","    shadow_split_idx = [int(whole_trainset.__len__()/2), int(whole_trainset.__len__()) -int(whole_trainset.__len__()/2)]\n","    trainset, shadow_trainset = torch.utils.data.random_split(whole_trainset, shadow_split_idx)\n","    \n","    shadow_split_idx = [int(whole_testset.__len__()/2), int(whole_testset.__len__()) -int(whole_testset.__len__()/2)]\n","    testset, shadow_testset = torch.utils.data.random_split(whole_testset, shadow_split_idx)\n","\n","    test_loader = DataLoader(testset, batch_size=FL_params.test_batch_size, shuffle=False, **kwargs)\n","    shadow_test_loader = DataLoader(shadow_testset, batch_size=FL_params.test_batch_size, shuffle=False, **kwargs)\n","\n","    split_index = [int(trainset.__len__()/FL_params.N_client)]*(FL_params.N_client-1)\n","    split_index.append(int(trainset.__len__() - int(trainset.__len__()/FL_params.N_client)*(FL_params.N_client-1)))\n","    client_dataset = torch.utils.data.random_split(trainset, split_index)\n","\n","    split_index = [int(shadow_trainset.__len__()/FL_params.N_client)]*(FL_params.N_client-1)\n","    split_index.append(int(shadow_trainset.__len__() - int(shadow_trainset.__len__()/FL_params.N_client)*(FL_params.N_client-1)))\n","    shadow_client_dataset = torch.utils.data.random_split(shadow_trainset, split_index)\n"," \n","    client_loaders = []\n","    shadow_client_loaders = []\n","    for ii in range(FL_params.N_client):\n","        client_loaders.append(DataLoader(client_dataset[ii], FL_params.local_batch_size, shuffle=False, **kwargs))\n","        shadow_client_loaders.append(DataLoader(shadow_client_dataset[ii], FL_params.local_batch_size, shuffle=False, **kwargs))\n","\n","    return client_loaders, test_loader, shadow_client_loaders, shadow_test_loader\n","\n","\n","def data_set(data_name):\n","    if not data_name in ['mnist','purchase','adult','cifar10']:\n","        raise TypeError('data_name should be a string, including mnist,purchase,adult,cifar10. ')\n","    \n","    # model: 2 conv. layers followed by 2 FC layers\n","    if(data_name == 'mnist'):\n","        trainset = datasets.MNIST('./data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ]))\n","\n","        testset = datasets.MNIST('./data', train=False, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ]))\n","        \n","    # model: ResNet-50\n","    elif(data_name == 'cifar10'):\n","        transform = transforms.Compose(\n","            [transforms.ToTensor(),\n","             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","        \n","        trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","        \n","        testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","    \n","    # model: 2 FC layers\n","    elif(data_name == 'purchase'):\n","        xx = np.load(\"./data/purchase/purchase_xx.npy\")\n","        yy = np.load(\"./data/purchase/purchase_y2.npy\")\n","        X_train, X_test, y_train, y_test = train_test_split(xx, yy, test_size=0.2, random_state=42)\n","        \n","        X_train_tensor = torch.Tensor(X_train).type(torch.FloatTensor)\n","        X_test_tensor = torch.Tensor(X_test).type(torch.FloatTensor)\n","        y_train_tensor = torch.Tensor(y_train).type(torch.LongTensor)\n","        y_test_tensor = torch.Tensor(y_test).type(torch.LongTensor)\n","        \n","        trainset = TensorDataset(X_train_tensor,y_train_tensor)\n","        testset = TensorDataset(X_test_tensor,y_test_tensor)\n","        \n","    # model: 2 FC layers\n","    elif(data_name == 'adult'):\n","        #load data\n","        file_path = \"./data/adult/\"\n","        data1 = pd.read_csv(file_path + 'adult.data', header=None)\n","        data2 = pd.read_csv(file_path + 'adult.test', header=None)\n","        data2 = data2.replace(' <=50K.', ' <=50K')    \n","        data2 = data2.replace(' >50K.', ' >50K')\n","        train_num = data1.shape[0]\n","        data = pd.concat([data1,data2])\n","       \n","        # data transform: str->int\n","        data = np.array(data, dtype=str)\n","        labels = data[:,14]\n","        le= LabelEncoder()\n","        le.fit(labels)\n","        labels = le.transform(labels)\n","        data = data[:,:-1]\n","        \n","        categorical_features = [1,3,5,6,7,8,9,13]\n","        for feature in categorical_features:\n","            le = LabelEncoder()\n","            le.fit(data[:, feature])\n","            data[:, feature] = le.transform(data[:, feature])\n","        data = data.astype(float)\n","        \n","        n_features = data.shape[1]\n","        numerical_features = list(set(range(n_features)).difference(set(categorical_features)))\n","        for feature in numerical_features:\n","            scaler = MinMaxScaler()\n","            sacled_data = scaler.fit_transform(data[:,feature].reshape(-1,1))\n","            data[:,feature] = sacled_data.reshape(-1)\n","        \n","        # OneHotLabel\n","        oh_encoder = ColumnTransformer(\n","            [('oh_enc', OneHotEncoder(sparse=False), categorical_features),], \n","            remainder='passthrough' )\n","        oh_data = oh_encoder.fit_transform(data)\n","        \n","        xx = oh_data\n","        yy = labels\n","        xx = preprocessing.scale(xx)\n","        yy = np.array(yy)\n","        \n","        xx = torch.Tensor(xx).type(torch.FloatTensor)\n","        yy = torch.Tensor(yy).type(torch.LongTensor)\n","        xx_train = xx[0:data1.shape[0],:]\n","        xx_test = xx[data1.shape[0]:,:]\n","        yy_train = yy[0:data1.shape[0]]\n","        yy_test = yy[data1.shape[0]:]\n","\n","        trainset = TensorDataset(xx_train,yy_train)\n","        testset = TensorDataset(xx_test,yy_test)\n","        \n","    return trainset, testset\n","\n","\n","\"\"\"\n","Array2Dataset: A class that can transform np.array(tensor matrix) to a torch.Dataset class.  \n","\"\"\"\n","class Array2Dataset(Dataset):\n","    def __init__(self, data, targets, transform=None):\n","        self.data = data\n","        self.targets = targets\n","        self.transform = transform\n","    def __getitem__(self, index):\n","        x = self.data[index,:]\n","        y = self.targets[index]\n","        return x, y\n","    def __len__(self):\n","        return len(self.data)\n","\n","```"],"metadata":{"id":"n51COge1AtTQ"}},{"cell_type":"markdown","source":["# `Fed_Unlearn_base.py`"],"metadata":{"id":"GCJn0MoGJkbK"}},{"cell_type":"markdown","source":["```python\n","import torch\n","import torch.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","import argparse\n","from torch.utils.data import DataLoader, Dataset\n","import copy\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import time\n","\n","from model_initiation import model_init\n","from data_preprocess import data_set\n","\n","from FL_base import fedavg, global_train_once, FL_Train, FL_Retrain\n","\n","\n","def federated_learning_unlearning(init_global_model, client_loaders, test_loader, FL_params):\n","    print(5*\"#\"+\"  Federated Learning Start  \"+5*\"#\")\n","    std_time = time.time()\n","    old_GMs, old_CMs = FL_Train(init_global_model, client_loaders, test_loader, FL_params)\n","    end_time = time.time()\n","    time_learn = (std_time - end_time)\n","    print(5*\"#\"+\"  Federated Learning End  \"+5*\"#\")\n","\n","    print('\\n')\n","    \"\"\"4.2 unlearning  a client, Federated Unlearning\"\"\"\n","    print(5*\"#\"+\"  Federated Unlearning Start  \"+5*\"#\")\n","    std_time = time.time()\n","    FL_params.if_unlearning = True\n","    FL_params.forget_client_idx = 2\n","    unlearn_GMs = unlearning(old_GMs, old_CMs, client_loaders, test_loader, FL_params)\n","    end_time = time.time()\n","    time_unlearn = (std_time - end_time)\n","    print(5*\"#\"+\"  Federated Unlearning End  \"+5*\"#\")\n","\n","    print('\\n')\n","    \"\"\"4.3 unlearning a client, Federated Unlearning without calibration\"\"\"\n","    print(5*\"#\"+\"  Federated Unlearning without Calibration Start  \"+5*\"#\")\n","    std_time = time.time()\n","    uncali_unlearn_GMs = unlearning_without_cali(old_GMs, old_CMs, FL_params)\n","    end_time = time.time()\n","    time_unlearn_no_cali = (std_time - end_time)\n","    print(5*\"#\"+\"  Federated Unlearning without Calibration End  \"+5*\"#\")\n","\n","    print(\" Learning time consuming = {} secods\".format(-time_learn))\n","    print(\" Unlearning time consuming = {} secods\".format(-time_unlearn)) \n","    print(\" Unlearning no Cali time consuming = {} secods\".format(-time_unlearn_no_cali))\n","\n","    return old_GMs, unlearn_GMs, uncali_unlearn_GMs, old_CMs\n","\n","\n","def unlearning(old_GMs, old_CMs, client_data_loaders, test_loader, FL_params):\n","    \"\"\"\n","    Parameters\n","    ----------\n","    old_global_models : list of DNN models\n","        In standard federated learning, all the global models from each round of training are saved.\n","    old_client_models : list of local client models\n","        In standard federated learning, the server collects all user models after each round of training.\n","    client_data_loaders : list of torch.utils.data.DataLoader\n","        This can be interpreted as each client user's own data, and each Dataloader corresponds to each user's data\n","    test_loader : torch.utils.data.DataLoader\n","        The loader for the test set used for testing\n","    FL_params : Argment()\n","        The parameter class used to set training parameters\n","\n","    Returns\n","    -------\n","    forget_global_model : One DNN model that has the same structure but different parameters with global_moedel\n","        DESCRIPTION.\n","    \"\"\"\n","\n","    if(FL_params.if_unlearning == False):\n","        raise ValueError('FL_params.if_unlearning should be set to True, if you want to unlearning with a certain user')\n","    if(not(FL_params.forget_client_idx in range(FL_params.N_client))):\n","        raise ValueError('FL_params.forget_client_idx is note assined correctly, forget_client_idx should in {}'.format(range(FL_params.N_client)))\n","    if(FL_params.unlearn_interval == 0 or FL_params.unlearn_interval >FL_params.global_epoch):\n","        raise ValueError('FL_params.unlearn_interval should not be 0, or larger than the number of FL_params.global_epoch')\n","\n","    old_global_models = copy.deepcopy(old_GMs)\n","    old_client_models = copy.deepcopy(old_CMs)\n","\n","    forget_client = FL_params.forget_client_idx\n","    for ii in range(FL_params.global_epoch):\n","        temp = old_client_models[ii*FL_params.N_client : ii*FL_params.N_client+FL_params.N_client]\n","        temp.pop(forget_client)#During Unlearn, the model saved by the forgotten user pops up\n","        old_client_models.append(temp)\n","    old_client_models = old_client_models[-FL_params.global_epoch:]\n","\n","    GM_intv = np.arange(0,FL_params.global_epoch+1, FL_params.unlearn_interval, dtype=np.int16())\n","    CM_intv  = GM_intv -1\n","    CM_intv = CM_intv[1:]\n","\n","    selected_GMs = [old_global_models[ii] for ii in GM_intv]\n","    selected_CMs = [old_client_models[jj] for jj in CM_intv]\n","\n","    \"\"\"1. First, complete the model overlay from the initial model to the first round of global train\"\"\"\n","    \"\"\"\n","    Since the inIT_model does not contain any information about the forgotten user at the start of the FL training, you just need to overlay the local Model of the other retained users, You can get the Global Model after the first round of global training.\n","    \"\"\"\n","    epoch = 0\n","    unlearn_global_models = list()\n","    unlearn_global_models.append(copy.deepcopy(selected_GMs[0]))\n","    \n","    new_global_model = fedavg(selected_CMs[epoch])\n","    unlearn_global_models.append(copy.deepcopy(new_global_model))\n","    print(\"Federated Unlearning Global Epoch  = {}\".format(epoch))\n","    \n","    \"\"\"2. Then, the first round of global model as a starting point, the model is gradually corrected\"\"\"\n","    \"\"\"\n","    In this step, the global Model obtained from the first round of global training was used as the new starting point for training, and a small amount of training was carried out with the data of the reserved user (a small amount means reducing the local epoch, i.e. Reduce the number of local training rounds for each user. The parameter forget_local_epoch_ratio is to control and reduce the number of local training rounds.) Gets the direction of iteration of the local Model parameter for each reserved user, starting with new_global_model.Note that this part of the user model is ref_client_models.\n","\n","    Then we use the old_client_models and old_global_models saved from the unforgotten FL training, and the ref_client_models and new_global_Model that we get when we forget a user,To build the global model for the next round\n","\n","\n","    (ref_client_models - new_global_model) / ||ref_client_models - new_global_model||, Indicates the direction of model parameter iteration starting with a new global model that removes a user.Mark the direction as step_direction\n","\n","    ||old_client_models - old_global_model||, Indicates the step size of the model parameter iteration starting with the old global model with a user removed.Step step_length\n","\n","    So, the final direction of the new reference model is step_direction*step_length + new_global_model。\n","    \"\"\"\n","    \"\"\"\n","    Intuitive explanation of this part: Usually in IID data, after the data is sharded, the direction of model parameter iteration is roughly the same.The basic idea is to take full advantage of the client-model parameter data saved in standard FL training, and then, by correcting this part of the parameter, apply it to the iteration of the new global model that forgets a user.\n","\n","    For unforgotten FL: oldGM_t--> oldCM0, oldCM1, oldCM2, oldCM3--> oldGM_t+1\n","    for unblearning FL: newGM_t-->newCM0, newCM1, newCM2, newCM3--> newGM_t+1\n","    oldGM_t and newGM_t essentially represents a different starting point for training. However, under the IID data, oldCM and newCM should converge in roughly the same direction.\n","    Therefore, we get newCM by using newcm-newgm_t as the starting point and training fewer rounds on user data, and then using (newcm-newgm_t)/|| newcm-newgm_t || as the current forgetting setting,\n","    Direction of model parameter iteration.Take || oldcm-oldgm_t || as the iteration step, and finally use || oldcm-oldgm_t ||*(newcm-newgm_t)/|| newcm-newgm_t |0 |1 for the iteration of the new model.\n","    FedEraser iterative formula: newGM_t+1 = newGM_t + ||oldCM - oldGM_t||*(newCM - newGM_t)/||newCM - newGM_t||\n","    \"\"\"\n","\n","    CONST_local_epoch = copy.deepcopy(FL_params.local_epoch)\n","    FL_params.local_epoch = np.ceil(FL_params.local_epoch*FL_params.forget_local_epoch_ratio)\n","    FL_params.local_epoch = np.int16(FL_params.local_epoch)\n","\n","    CONST_global_epoch = copy.deepcopy(FL_params.global_epoch)\n","    FL_params.global_epoch = CM_intv.shape[0]\n","\n","    print('Local Calibration Training epoch = {}'.format(FL_params.local_epoch))\n","    for epoch in range(FL_params.global_epoch):\n","        if(epoch == 0):\n","            continue\n","        print(\"Federated Unlearning Global Epoch  = {}\".format(epoch))\n","        global_model = unlearn_global_models[epoch]\n","\n","        new_client_models  = global_train_once(global_model, client_data_loaders, test_loader, FL_params)\n","\n","        new_GM = unlearning_step_once(selected_CMs[epoch], new_client_models, selected_GMs[epoch+1], global_model)\n","        \n","        unlearn_global_models.append(new_GM)\n","    FL_params.local_epoch = CONST_local_epoch\n","    FL_params.global_epoch = CONST_global_epoch\n","    return unlearn_global_models\n","    \n","def unlearning_step_once(old_client_models, new_client_models, global_model_before_forget, global_model_after_forget):\n","    \"\"\"\n","    Parameters\n","    ----------\n","    old_client_models : list of DNN models\n","        When there is no choice to forget (if_forget=False), use the normal continuous learning training to get each user's local model.The old_client_models do not contain models of users that are forgotten.\n","        Models that require forgotten users are not discarded in the Forget function\n","    ref_client_models : list of DNN models\n","        When choosing to forget (if_forget=True), train with the same Settings as before, except that the local epoch needs to be reduced, other parameters are set in the same way.\n","        Using the above training Settings, the new global model is taken as the starting point and the reference model is trained.The function of the reference model is to identify the direction of model parameter iteration starting from the new global model\n","        \n","    global_model_before_forget : The old global model\n","        DESCRIPTION.\n","    global_model_after_forget : The New global model\n","        DESCRIPTION.\n","\n","    Returns\n","    -------\n","    return_global_model : After one iteration, the new global model under the forgetting setting\n","\n","    \"\"\"\n","    old_param_update = dict() # Model Params： oldCM - oldGM_t\n","    new_param_update = dict() # Model Params： newCM - newGM_t\n","\n","    new_global_model_state = global_model_after_forget.state_dict()#newGM_t\n","\n","    return_model_state = dict() # newGM_t + ||oldCM - oldGM_t||*(newCM - newGM_t)/||newCM - newGM_t||\n","\n","    assert len(old_client_models) == len(new_client_models)\n","\n","    for layer in global_model_before_forget.state_dict().keys():\n","        old_param_update[layer] = 0*global_model_before_forget.state_dict()[layer]\n","        new_param_update[layer] = 0*global_model_before_forget.state_dict()[layer]\n","\n","        return_model_state[layer] = 0*global_model_before_forget.state_dict()[layer]\n","\n","        for ii in range(len(new_client_models)):\n","            old_param_update[layer] += old_client_models[ii].state_dict()[layer]\n","            new_param_update[layer] += new_client_models[ii].state_dict()[layer]\n","        old_param_update[layer] /= (ii+1) # Model Params： oldCM\n","        new_param_update[layer] /= (ii+1) # Model Params： newCM\n","\n","        old_param_update[layer] = old_param_update[layer] - global_model_before_forget.state_dict()[layer] # oldCM - oldGM_t\n","        new_param_update[layer] = new_param_update[layer] - global_model_after_forget.state_dict()[layer] # newCM - newGM_t\n","\n","        step_length = torch.norm(old_param_update[layer]) #||oldCM - oldGM_t||\n","        step_direction = new_param_update[layer]/torch.norm(new_param_update[layer]) # (newCM - newGM_t)/||newCM - newGM_t||\n","\n","        return_model_state[layer] = new_global_model_state[layer] + step_length*step_direction\n","    \n","    return_global_model = copy.deepcopy(global_model_after_forget)\n","    \n","    return_global_model.load_state_dict(return_model_state)\n","    \n","    return return_global_model\n","    \n","    \n","def unlearning_without_cali(old_global_models, old_client_models, FL_params):\n","    \"\"\"\n","    Parameters\n","    ----------\n","    old_client_models : list of DNN models\n","        All user local update models are saved during the federated learning and training process that is not forgotten.\n","    FL_params : parameters\n","        All parameters in federated learning and federated forgetting learning\n","\n","    Returns\n","    -------\n","    global_models : List of DNN models\n","        In each update round, the client model of the user who needs to be forgotten is removed, and the parameters of other users' client models are directly superimposing to form the new Global Model of each round\n","\n","    \"\"\"\n","    \"\"\"\n","    The basic process is as follows: For unforgotten FL:oldGM_t--> oldCM0, oldCM1, oldCM2, oldCM3--> oldGM_t+1\n","                 For unlearning FL: newGM_t-->The parameters of oldCM and oldGM were directly leveraged to update global model--> newGM_t+1\n","    The update process is as follows: newGM_t+1 = (oldCM - oldGM_t) + newGM_t\n","    \"\"\"\n","    if(FL_params.if_unlearning == False):\n","        raise ValueError('FL_params.if_unlearning should be set to True, if you want to unlearning with a certain user')\n","\n","    if(not(FL_params.forget_client_idx in range(FL_params.N_client))):\n","        raise ValueError('FL_params.forget_client_idx is note assined correctly, forget_client_idx should in {}'.format(range(FL_params.N_client)))\n","    forget_client = FL_params.forget_client_idx\n","\n","\n","    for ii in range(FL_params.global_epoch):\n","        temp = old_client_models[ii*FL_params.N_client : ii*FL_params.N_client+FL_params.N_client]\n","        temp.pop(forget_client)\n","        old_client_models.append(temp)\n","    old_client_models = old_client_models[-FL_params.global_epoch:]\n","\n","    uncali_global_models = list()\n","    uncali_global_models.append(copy.deepcopy(old_global_models[0]))\n","    epoch = 0\n","    uncali_global_model = fedavg(old_client_models[epoch])\n","    uncali_global_models.append(copy.deepcopy(uncali_global_model))\n","    print(\"Federated Unlearning without Clibration Global Epoch  = {}\".format(epoch))\n","\n","    \"\"\"\n","    new_GM_t+1 = newGM_t + (oldCM_t - oldGM_t)\n","\n","    For standard federated learning:oldGM_t --> oldCM_t --> oldGM_t+1\n","    For accumulatring:    newGM_t --> (oldCM_t - oldGM_t) --> oldGM_t+1\n","    For uncalibrated federated forgotten learning, the parameter update of the unforgotten user in standard federated learning is used to directly overlay the new global model to obtain the next round of new global model.\n","    \"\"\"\n","    old_param_update = dict() # (oldCM_t - oldGM_t)\n","    return_model_state = dict() # newGM_t+1\n","    \n","    for epoch in range(FL_params.global_epoch):\n","        if(epoch == 0):\n","            continue\n","        print(\"Federated Unlearning Global Epoch  = {}\".format(epoch))\n","\n","        current_global_model = uncali_global_models[epoch] # newGM_t\n","        current_client_models = old_client_models[epoch] # oldCM_t\n","        old_global_model = old_global_models[epoch] # oldGM_t\n","        # global_model_before_forget = old_global_models[epoch]#old_GM_t\n","\n","        for layer in current_global_model.state_dict().keys():\n","            # State variable initialization\n","            old_param_update[layer] = 0*current_global_model.state_dict()[layer]\n","            return_model_state[layer] = 0*current_global_model.state_dict()[layer]\n","            \n","            for ii in range(len(current_client_models)):\n","                old_param_update[layer] += current_client_models[ii].state_dict()[layer]\n","            old_param_update[layer] /= (ii+1) # oldCM_t\n","            \n","            old_param_update[layer] = old_param_update[layer] - old_global_model.state_dict()[layer] # oldCM_t - oldGM_t\n","\n","            return_model_state[layer] = current_global_model.state_dict()[layer] + old_param_update[layer] # newGM_t + (oldCM_t - oldGM_t)\n","            \n","        return_global_model = copy.deepcopy(old_global_models[0])\n","        return_global_model.load_state_dict(return_model_state)\n","\n","        uncali_global_models.append(return_global_model)\n","\n","    return uncali_global_models\n","\n","```"],"metadata":{"id":"rgoIl-ctIdv9"}},{"cell_type":"markdown","source":["# `Fed_Unlearn_main.py`"],"metadata":{"id":"szsmARK-JuJy"}},{"cell_type":"markdown","source":["```python\n","import torch\n","import torch.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","import argparse\n","from torch.utils.data import DataLoader, Dataset\n","import copy\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import time \n","\n","from model_initiation import model_init\n","from data_preprocess import data_init, data_init_with_shadow\n","from FL_base import global_train_once\n","from FL_base import fedavg\n","from FL_base import test\n","\n","from FL_base import FL_Train, FL_Retrain\n","from Fed_Unlearn_base import unlearning, unlearning_without_cali, federated_learning_unlearning\n","from membership_inference import train_attack_model, attack\n","\n","\"\"\"Step 0. Initialize Federated Unlearning parameters\"\"\"\n","class Arguments():\n","    def __init__(self):\n","        # Federated Learning Settings\n","        self.N_total_client = 100\n","        self.N_client = 10\n","        self.data_name = 'mnist' # purchase, cifar10, mnist, adult\n","        self.global_epoch = 20\n","        self.local_epoch = 10\n","\n","        # Model Training Settings\n","        self.local_batch_size = 64\n","        self.local_lr = 0.005\n","\n","        self.test_batch_size = 64\n","        self.seed = 1\n","        self.save_all_model = True\n","        self.cuda_state = torch.cuda.is_available()\n","        self.use_gpu = True\n","        self.train_with_test = False\n","        \n","        # Federated Unlearning Settings\n","        self.unlearn_interval = 1 # Used to control how many rounds the model parameters are saved. 1 represents the parameter saved once per round  N_itv in our paper.\n","        self.forget_client_idx = 2 # If want to forget, change None to the client index\n","                                # If this parameter is set to False, only the global model after the final training is completed is output\n","        self.if_retrain = True # If set to True, the global model is retrained using the FL-Retrain function, and data corresponding to the user for the forget_client_IDx number is discarded.\n","        \n","        self.if_unlearning = False # If set to False, the global_train_once function will not skip users that need to be forgotten;If set to True, global_train_once skips the forgotten user during training\n","        \n","        self.forget_local_epoch_ratio = 0.5 # When a user is selected to be forgotten, other users need to train several rounds of on-line training in their respective data sets to obtain the general direction of model convergence in order to provide the general direction of model convergence.\n","        # forget_local_epoch_ratio*local_epoch Is the number of rounds of local training when we need to get the convergence direction of each local model\n","        # self.mia_oldGM = False\n","\n","def Federated_Unlearning():\n","    \"\"\"Step 1.Set the parameters for Federated Unlearning\"\"\"\n","    FL_params = Arguments()\n","    torch.manual_seed(FL_params.seed)\n","    # kwargs for data loader \n","    print(60*'=')\n","    print(\"Step1. Federated Learning Settings \\n We use dataset: \"+FL_params.data_name+(\" for our Federated Unlearning experiment.\\n\"))\n","\n","    \"\"\"Step 2. construct the necessary user private data set required for federated learning, as well as a common test set\"\"\"\n","    print(60 * '=')\n","    print(\"Step2. Client data loaded, testing data loaded!!!\\n       Initial Model loaded!!!\")\n","    init_global_model = model_init(FL_params.data_name)\n","    client_all_loaders, test_loader = data_init(FL_params)\n","\n","    selected_clients=np.random.choice(range(FL_params.N_total_client),size=FL_params.N_client, replace=False)\n","    client_loaders = list()\n","    for idx in selected_clients:\n","        client_loaders.append(client_all_loaders[idx])\n","    # client_all_loaders = client_loaders[selected_clients]\n","    # client_loaders, test_loader, shadow_client_loaders, shadow_test_loader = data_init_with_shadow(FL_params)\n","    \"\"\"\n","    This section of the code gets the initialization model init Global Model\n","    User data loader for FL training Client_loaders and test data loader Test_loader\n","    User data loader for covert FL training, Shadow_client_loaders, and test data loader Shadowl_test_loader\n","    \"\"\"\n","\n","    \"\"\"Step 3. Select a client's data to forget, 1.Federated Learning, 2.Unlearning(FedEraser), and 3.(Accumulating)Unlearing without calibration\"\"\"\n","    print(60*'=')\n","    print(\"Step3. Fedearated Learning and Unlearning Training...\")\n","    # \n","    old_GMs, unlearn_GMs, uncali_unlearn_GMs, old_CMs = federated_learning_unlearning(\n","        init_global_model, \n","        client_loaders, \n","        test_loader, \n","        FL_params\n","    )\n","\n","    if(FL_params.if_retrain == True):\n","        \n","        t1 = time.time()\n","        retrain_GMs = FL_Retrain(init_global_model, client_loaders, test_loader, FL_params)\n","        t2 = time.time()\n","        print(\"Time using = {} seconds\".format(t2-t1))\n","\n","    \"\"\"Step 4  The member inference attack model is built based on the output of the Target Global Model on client_loaders and test_loaders.In this case, we only do the MIA attack on the model at the end of the training\"\"\"\n","    \n","    \"\"\"MIA:Based on the output of oldGM model, MIA attack model was built, and then the attack model was used to attack unlearn GM. If the attack accuracy significantly decreased, it indicated that our unlearn method was indeed effective to remove the user's information\"\"\"\n","    print(60*'=')\n","    print(\"Step4. Membership Inference Attack aganist GM...\")\n","\n","    T_epoch = -1\n","    # MIA setting:Target model == Shadow Model\n","    old_GM = old_GMs[T_epoch]\n","    attack_model = train_attack_model(old_GM, client_loaders, test_loader, FL_params)\n","\n","    print(\"\\nEpoch  = {}\".format(T_epoch))\n","    print(\"Attacking against FL Standard  \")\n","    target_model = old_GMs[T_epoch]\n","    (ACC_old, PRE_old) = attack(target_model, attack_model, client_loaders, test_loader, FL_params)\n","\n","    if(FL_params.if_retrain == True):\n","        print(\"Attacking against FL Retrain  \")\n","        target_model = retrain_GMs[T_epoch]\n","        (ACC_retrain, PRE_retrain) = attack(target_model, attack_model, client_loaders, test_loader, FL_params)\n","\n","    print(\"Attacking against FL Unlearn  \")\n","    target_model = unlearn_GMs[T_epoch]\n","    (ACC_unlearn, PRE_unlearn) = attack(target_model, attack_model, client_loaders, test_loader, FL_params)\n","\n","\n","if __name__=='__main__':\n","    Federated_Unlearning()\n","```"],"metadata":{"id":"2yL2_Nw2Jywy"}},{"cell_type":"markdown","source":["# `FL_base.py`"],"metadata":{"id":"iN07Cv6PKMYq"}},{"cell_type":"markdown","source":["```python\n","import torch\n","import torch.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","import argparse\n","from torch.utils.data import DataLoader, Dataset\n","import copy\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import time\n","\n","from model_initiation import model_init\n","from data_preprocess import data_set\n","\n","\n","def FL_Train(init_global_model, client_data_loaders, test_loader, FL_params):\n","    all_global_models = list()\n","    all_client_models = list()\n","    global_model = init_global_model\n","\n","    all_global_models.append(copy.deepcopy(global_model))\n","\n","    for epoch in range(FL_params.global_epoch):\n","        client_models = global_train_once(global_model, client_data_loaders, test_loader, FL_params)\n","        # IMPORTANT: It is IMPORTANT to note here that global_train_once is trained directly on the input client_models during training, so the output's client_models are the same set of models as the input's client_models, except that the input is untrained while the output is trained.\n","        # Therefore, in order to implement Federated Unlearning, we need to save the models in Client -- Models before global Train.You can use DeepCopy, or hard disk IO.\n","        all_client_models += client_models\n","        global_model = fedavg(client_models)\n","        # print(30*'^')\n","        print(\"Global Federated Learning epoch = {}\".format(epoch))\n","        # test(global_model, test_loader)\n","        # print(30*'v')\n","        # print(len(all_client_models))\n","        all_global_models.append(copy.deepcopy(global_model))\n","\n","    return all_global_models, all_client_models\n","\n","\n","def FL_Retrain(init_global_model, client_data_loaders, test_loader, FL_params):\n","    if(FL_params.if_retrain == False):\n","        raise ValueError('FL_params.if_retrain should be set to True, if you want to retrain FL model')\n","    if(FL_params.forget_client_idx not in range(FL_params.N_client)):\n","        raise ValueError('FL_params.forget_client_idx should be in [{}], if you want to use standard FL train with forget the certain client dataset.'.format(range(FL_params.N_client)))\n","    # forget_idx= FL_params.forget_idx\n","    print('\\n')\n","    print(5*\"#\"+\"  Federated Retraining Start  \"+5*\"#\")\n","    # std_time = time.time()\n","    print(\"Federated Retrain with Forget Client NO.{}\".format(FL_params.forget_client_idx))\n","    retrain_GMs = list()\n","    all_client_models = list()\n","    retrain_GMs.append(copy.deepcopy(init_global_model))\n","    global_model = init_global_model\n","    for epoch in range(FL_params.global_epoch):\n","        client_models = global_train_once(global_model, client_data_loaders, test_loader, FL_params)\n","        # IMPORTANT：It is important to note that global_train_once is trained directly on the input client_models during training, so the output's client_models are the same set of models as the input's client_models, except that the input is untrained while the output is trained.\n","        #IMPORTANT: Therefore, in order to implement Federated Unlearning, we need to save the models in Client -- Models before global Train.You can use DeepCopy, or hard disk IO.\n","        global_model = fedavg(client_models)\n","        print(\"Global Retraining epoch = {}\".format(epoch))\n","        retrain_GMs.append(copy.deepcopy(global_model))\n","        \n","        all_client_models += client_models\n","    print(5*\"#\"+\"  Federated Retraining End  \"+5*\"#\")\n","    return retrain_GMs\n","\n","\n","\"\"\"\n","Function:\n","For the global round of training, the data and optimizer of each global_ModelT is used. The global model of the previous round is the initial point and the training begins.\n","NOTE: The global model inputed is the global model for the previous round\n","      The output client_Models is the model that each user trained separately.\n","\"\"\"\n","# training sub function\n","def global_train_once(global_model, client_data_loaders, test_loader, FL_params):\n","    # Using the model, optimizer, and data of each client, training the initial model with client_models, updating the UPODate -- client_models using the client user's local data and optimizer\n","    # Note: It is important to Note that global_train_once is only a global update to the parameters of the model\n","    # update_client_models = list()\n","    device = torch.device(\"cuda\" if FL_params.use_gpu*FL_params.cuda_state else \"cpu\")\n","    device_cpu = torch.device(\"cpu\")\n","\n","    client_models = []\n","    client_sgds = []\n","    for ii in range(FL_params.N_client):\n","        client_models.append(copy.deepcopy(global_model))\n","        client_sgds.append(optim.SGD(client_models[ii].parameters(), lr=FL_params.local_lr, momentum=0.9))\n","\n","    for client_idx in range(FL_params.N_client):\n","        if(((FL_params.if_retrain) and (FL_params.forget_client_idx == client_idx)) or ((FL_params.if_unlearning) and (FL_params.forget_client_idx == client_idx))):\n","            continue\n","        # if((FL_params.if_unlearning) and (FL_params.forget_client_idx == client_idx)):\n","        #     continue\n","        # print(30*'-')\n","        # print(\"Now training Client No.{}  \".format(client_idx))\n","        model = client_models[client_idx]\n","        optimizer = client_sgds[client_idx]\n","\n","        model.to(device)\n","        model.train()\n","\n","        #local training\n","        for local_epoch in range(FL_params.local_epoch):\n","            for batch_idx, (data, target) in enumerate(client_data_loaders[client_idx]):\n","                data = data.to(device)\n","                target = target.to(device)\n","\n","                optimizer.zero_grad()\n","                pred = model(data)\n","                criteria = nn.CrossEntropyLoss()\n","                loss = criteria(pred, target)\n","                loss.backward()\n","                optimizer.step()\n","\n","            if(FL_params.train_with_test):\n","                print(\"Local Client No. {}, Local Epoch: {}\".format(client_idx, local_epoch))\n","                test(model, test_loader)\n","\n","        # if(FL_params.use_gpu*FL_params.cuda_state):\n","        model.to(device_cpu)\n","        client_models[client_idx] = model\n","\n","    if(((FL_params.if_retrain) and (FL_params.forget_client_idx == client_idx))):\n","        #Only retrian needs to discard the Client model;If it's not in Retrain, there's no need to discard the model\n","        client_models.pop(FL_params.forget_client_idx)\n","        return client_models\n","    elif((FL_params.if_unlearning) and (FL_params.forget_client_idx in range(FL_params.N_client))):\n","        client_models.pop(FL_params.forget_client_idx)\n","        return client_models\n","    else:\n","        return client_models\n","\n","\n","\"\"\"\n","Function:\n","Test the performance of the model on the test set\n","\"\"\"\n","def test(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    test_acc = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            output = model(data)\n","            criteria = nn.CrossEntropyLoss()\n","            test_loss += criteria(output, target) # sum up batch loss\n","\n","            pred = torch.argmax(output,axis=1)\n","            test_acc += accuracy_score(pred,target)\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_acc = test_acc/np.ceil(len(test_loader.dataset)/test_loader.batch_size)\n","    print('Test set: Average loss: {:.8f}'.format(test_loss))         \n","    print('Test set: Average acc:  {:.4f}'.format(test_acc))    \n","    return (test_loss, test_acc)\n","\n","\n","\"\"\"\n","Function:\n","FedAvg\n","\"\"\"    \n","def fedavg(local_models):\n","# def fedavg(local_models, local_model_weights=None):\n","    \"\"\"\n","    Parameters\n","    ----------\n","    local_models : list of local models\n","        DESCRIPTION. In federated learning, with the global_model as the initial model, each user uses a collection of local models updated with their local data.\n","    local_model_weights : tensor or array\n","        DESCRIPTION. The weight of each local model is usually related to the accuracy rate and number of data of the local model.(Bypass)\n","\n","    Returns\n","    -------\n","    update_global_model\n","        Updated global model using fedavg algorithm\n","    \"\"\"\n","    # N = len(local_models)\n","    # new_global_model = copy.deepcopy(local_models[0])\n","    # print(len(local_models))\n","    global_model = copy.deepcopy(local_models[0])\n","    avg_state_dict = global_model.state_dict()\n","\n","    local_state_dicts = list()\n","    for model in local_models:\n","        local_state_dicts.append(model.state_dict())\n","\n","    for layer in avg_state_dict.keys():\n","        avg_state_dict[layer] *= 0 \n","        for client_idx in range(len(local_models)):\n","            avg_state_dict[layer] += local_state_dicts[client_idx][layer]\n","        avg_state_dict[layer] /= len(local_models)\n","\n","    global_model.load_state_dict(avg_state_dict)\n","    return global_model\n","\n","```"],"metadata":{"id":"R7uI9f2nKO8S"}},{"cell_type":"markdown","source":["# `membership_inference.py`"],"metadata":{"id":"-0QlCpo8KpoD"}},{"cell_type":"markdown","source":["```python\n","import torch\n","import torch.functional as F\n","import torch.nn as nn\n","from torch.nn.functional import softmax\n","import torch.optim as optim\n","import argparse\n","from torch.utils.data import DataLoader, Dataset\n","import copy\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","from model_initiation import model_init\n","from data_preprocess import data_set\n","from FL_base import global_train_once\n","from FL_base import fedavg\n","from FL_base import test\n","from sklearn.linear_model import LogisticRegression\n","from FL_base import FL_Train, FL_Retrain\n","from Fed_Unlearn_base import unlearning, unlearning_without_cali, federated_learning_unlearning\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import train_test_split\n","\n","\n","def attack(target_model, attack_model, client_loaders, test_loader, FL_params):\n","    n_class_dict = dict()\n","    n_class_dict['adult'] = 2\n","    n_class_dict['purchase'] = 2\n","    n_class_dict['mnist'] = 10\n","    n_class_dict['cifar10'] = 10\n","    \n","    N_class = n_class_dict[FL_params.data_name]\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    target_model.to(device)\n","\n","    target_model.eval()\n","\n","    # The predictive output of forgotten user data after passing through the target model.\n","    unlearn_X = torch.zeros([1,N_class])\n","    unlearn_X = unlearn_X.to(device)\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(client_loaders[FL_params.forget_client_idx]):\n","            data = data.to(device)\n","            out = target_model(data)\n","            unlearn_X = torch.cat([unlearn_X, out])\n","\n","    unlearn_X = unlearn_X[1:,:]\n","    unlearn_X = softmax(unlearn_X,dim = 1)\n","    unlearn_X = unlearn_X.cpu().detach().numpy()\n","\n","    unlearn_X.sort(axis=1)\n","    unlearn_y = np.ones(unlearn_X.shape[0])\n","    unlearn_y = unlearn_y.astype(np.int16)\n","\n","    N_unlearn_sample = len(unlearn_y)\n","\n","    # Test data, predictive output obtained after passing the target model\n","    test_X = torch.zeros([1, N_class])\n","    test_X = test_X.to(device)\n","    with torch.no_grad():\n","        for _, (data, target) in enumerate(test_loader):\n","            data = data.to(device)\n","            out = target_model(data)\n","            test_X = torch.cat([test_X, out])\n","            \n","            if(test_X.shape[0] > N_unlearn_sample):\n","                break\n","    test_X = test_X[1:N_unlearn_sample+1,:]\n","    test_X = softmax(test_X,dim = 1)\n","    test_X = test_X.cpu().detach().numpy()\n","\n","    test_X.sort(axis=1)\n","    test_y = np.zeros(test_X.shape[0])\n","    test_y = test_y.astype(np.int16)\n","\n","    # The data of the forgotten user passed through the output of the target model, and the data of the test set passed through the output of the target model were spliced together\n","    #The balanced data set that forms the 50% train 50% test.\n","    XX = np.vstack((unlearn_X, test_X))\n","    YY = np.hstack((unlearn_y, test_y))\n","\n","    pred_YY = attack_model.predict(XX)\n","    pre = precision_score(YY, pred_YY, pos_label=1)\n","    rec = recall_score(YY, pred_YY, pos_label=1)\n","    print(\"MIA Attacker precision = {:.4f}\".format(pre))\n","    print(\"MIA Attacker recall = {:.4f}\".format(rec))\n","    \n","    return (pre, rec)\n","\n","\n","def train_attack_model(shadow_old_GM, shadow_client_loaders, shadow_test_loader, FL_params):\n","    shadow_model = shadow_old_GM\n","    n_class_dict = dict()\n","    n_class_dict['adult'] = 2\n","    n_class_dict['purchase'] = 2\n","    n_class_dict['mnist'] = 10\n","    n_class_dict['cifar10'] = 10\n","\n","    N_class = n_class_dict[FL_params.data_name]\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    shadow_model.to(device)\n","\n","    shadow_model.eval()\n","    pred_4_mem = torch.zeros([1,N_class])\n","    pred_4_mem = pred_4_mem.to(device)\n","    with torch.no_grad():\n","        for ii in range(len(shadow_client_loaders)):\n","            data_loader = shadow_client_loaders[ii]\n","            \n","            for batch_idx, (data, target) in enumerate(data_loader):\n","                    data = data.to(device)\n","                    out = shadow_model(data)\n","                    pred_4_mem = torch.cat([pred_4_mem, out])\n","    pred_4_mem = pred_4_mem[1:,:]\n","    pred_4_mem = softmax(pred_4_mem,dim = 1)\n","    pred_4_mem = pred_4_mem.cpu()\n","    pred_4_mem = pred_4_mem.detach().numpy()\n","\n","    ####\n","    pred_4_nonmem = torch.zeros([1,N_class])\n","    pred_4_nonmem = pred_4_nonmem.to(device)\n","    with torch.no_grad():\n","        for batch, (data, target) in enumerate(shadow_test_loader):\n","            data = data.to(device)\n","            out = shadow_model(data)\n","            pred_4_nonmem = torch.cat([pred_4_nonmem, out])\n","    pred_4_nonmem = pred_4_nonmem[1:,:]\n","    pred_4_nonmem = softmax(pred_4_nonmem,dim = 1)\n","    pred_4_nonmem = pred_4_nonmem.cpu()\n","    pred_4_nonmem = pred_4_nonmem.detach().numpy()\n","\n","    att_y = np.hstack((np.ones(pred_4_mem.shape[0]), np.zeros(pred_4_nonmem.shape[0])))\n","    att_y = att_y.astype(np.int16)\n","    \n","    att_X = np.vstack((pred_4_mem, pred_4_nonmem))\n","    att_X.sort(axis=1)\n","    \n","    X_train,X_test, y_train, y_test = train_test_split(att_X, att_y, test_size = 0.1)\n","    \n","    attacker = XGBClassifier(n_estimators = 300,\n","                              n_jobs = -1,\n","                                max_depth = 30,\n","                              objective = 'binary:logistic',\n","                              booster=\"gbtree\",\n","                               scale_pos_weight = pred_4_nonmem.shape[0]/pred_4_mem.shape[0]\n","                              )\n","\n","    attacker.fit(X_train, y_train)\n","\n","    return attacker\n","\n","```"],"metadata":{"id":"f8OwPv5hKrQT"}},{"cell_type":"markdown","source":["# `model_initiation.py`"],"metadata":{"id":"nscZtpcwK7Iz"}},{"cell_type":"markdown","source":["```python\n","\"\"\"\n","Adapted from FedEraser code\n","\"\"\"\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","\n","def model_init(data_name):\n","    if(data_name == 'mnist'):\n","        model = Net_mnist()\n","    elif(data_name == 'cifar10'):\n","        model = Net_cifar10()\n","    elif(data_name == 'purchase'):\n","        model = Net_purchase()\n","    elif(data_name == 'adult'):\n","        model = Net_adult()\n","    return model\n","\n","\n","class Net_mnist(nn.Module):\n","    def __init__(self):\n","        super(Net_mnist, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n","        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n","        self.fc1 = nn.Linear(4*4*50, 500)\n","        self.fc2 = nn.Linear(500, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = x.view(-1, 4*4*50)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","\n","class Net_purchase(nn.Module):\n","    def __init__(self):\n","        super(Net_purchase, self).__init__()\n","        self.fc1 = nn.Linear(600, 300)\n","        self.fc2 = nn.Linear(300, 50)\n","        self.fc3 = nn.Linear(50,2)\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        return x\n","\n","\n","class Net_adult(nn.Module):\n","    def __init__(self):\n","        super(Net_adult, self).__init__()\n","        self.fc1 = nn.Linear(108, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","        self.fc3 = nn.Linear(10,2)\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        return x     \n","\n","\n","class Net_cifar10(nn.Module):\n","    def __init__(self):\n","        super(Net_cifar10, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","class All_CNN(nn.Module):\n","    def __init__(self, filters_percentage=1., n_channels=3, num_classes=10, dropout=False, batch_norm=True):\n","        super(All_CNN, self).__init__()\n","        n_filter1 = int(96 * filters_percentage)\n","        n_filter2 = int(192 * filters_percentage)\n","        self.features = nn.Sequential(\n","            Conv(n_channels, n_filter1, kernel_size=3, batch_norm=batch_norm),\n","            Conv(n_filter1, n_filter1, kernel_size=3, batch_norm=batch_norm),\n","            Conv(n_filter1, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm),\n","            nn.Dropout(inplace=True) if dropout else Identity(),\n","            Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm),\n","            Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm),\n","            Conv(n_filter2, n_filter2, kernel_size=3, stride=2, padding=1, batch_norm=batch_norm),  # 14\n","            nn.Dropout(inplace=True) if dropout else Identity(),\n","            Conv(n_filter2, n_filter2, kernel_size=3, stride=1, batch_norm=batch_norm),\n","            Conv(n_filter2, n_filter2, kernel_size=1, stride=1, batch_norm=batch_norm),\n","            nn.AvgPool2d(8),\n","            Flatten(),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(n_filter2, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        features = self.features(x)\n","        output = self.classifier(features)\n","        return output  \n","\n","\n","class Conv(nn.Sequential):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None, output_padding=0,\n","                 activation_fn=nn.ReLU, batch_norm=True, transpose=False):\n","        if padding is None:\n","            padding = (kernel_size - 1) // 2\n","        model = []\n","        if not transpose:\n","            model += [nn.Conv2d(\n","                in_channels, \n","                out_channels, \n","                kernel_size=kernel_size, \n","                stride=stride, \n","                padding=padding,\n","                bias=not batch_norm\n","            )]\n","        else:\n","            model += [nn.ConvTranspose2d(\n","                in_channels, \n","                out_channels, \n","                kernel_size, \n","                stride=stride, \n","                padding=padding,\n","                output_padding=output_padding, \n","                bias=not batch_norm\n","            )]\n","        if batch_norm:\n","            model += [nn.BatchNorm2d(out_channels, affine=True)]\n","        model += [activation_fn()]\n","        super(Conv, self).__init__(*model) \n","\n","\n","class Identity(nn.Module):\n","    def __init__(self):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, x):\n","        return x  \n","\n","\n","class Flatten(nn.Module):\n","    def __init__(self):\n","        super(Flatten, self).__init__()\n","    def forward(self,x):\n","        return x.view(x.size(0), -1)\n","```"],"metadata":{"id":"fmp2WlFZK9JT"}},{"cell_type":"markdown","source":["# References\n","\n","- G. Liu, X. Ma, Y. Yang, C. Wang, and J. Liu, “FedEraser: Enabling Efficient Client-Level Data Removal from Federated Learning Models,” in 2021 IEEE/ACM 29th International Symposium on Quality of Service (IWQOS), 2021, pp. 1–10. [[Paper](https://ieeexplore.ieee.org/abstract/document/9521274)]"],"metadata":{"id":"GbIJ-3IEI3_L"}}]}